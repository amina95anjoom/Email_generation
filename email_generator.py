# -*- coding: utf-8 -*-
"""Email_gpt3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b9NGxLhcwloMx9PRSMC8Mwuy4yLjVsTa
"""

import openai
import torch
from transformers import AutoModelForSeq2SeqLM, MBartTokenizer
from transformers import pipeline 
class email_generator:
        
    openai.api_key = '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'

    def generate_email(self, userPrompt =" professionall email", start="Dear" ,end="Yours sincerely"):
      

        response = openai.Completion.create(
        engine="davinci",
        prompt=userPrompt + "\n\n" + start,
        temperature=0.71,
        max_tokens=150,
        top_p=1,
        frequency_penalty=0.36,
        presence_penalty=0.75
        )
        return response.get("choices")[0]['text']
    

    def Email_out(self, sample):
       
        changed = list(sample)
        for i, c in enumerate(changed):
            if(c == ' ' or c =='  ' or c =='   ' or c=='\n' or c=='\n\n'):
                changed[i] = '+'
                result=''.join(changed)
        return result
    
    def generate_arabic(self,result):
        inputs=result
        
       # model_nm="akhooli/mbart-large-cc25-en-ar"
        #max_length=500
        #transulator=pipeline("translation",model=model_nm)
       
        model =AutoModelForSeq2SeqLM.from_pretrained("akhooli/mbart-large-cc25-en-ar")
        tokenizer = MBartTokenizer.from_pretrained("akhooli/mbart-large-cc25-en-ar")
        batch = tokenizer.prepare_seq2seq_batch(src_texts=[inputs],
                                                src_lang="en_XX")
        translated_tokens = model.generate(**batch,
                                           decoder_start_token_id=tokenizer.lang_code_to_id["ar_AR"])
        translation = tokenizer.batch_decode(translated_tokens,
                                             skip_special_tokens=True)[0]
        return translation

